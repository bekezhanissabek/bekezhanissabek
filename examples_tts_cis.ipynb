{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bekezhanissabek/bekezhanissabek/blob/main/examples_tts_cis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ditto-Talking-Head"
      ],
      "metadata": {
        "id": "8Hj0U65CajsG"
      },
      "id": "8Hj0U65CajsG"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/antgroup/ditto-talkinghead"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1ByM-pkal-m",
        "outputId": "64559042-c1bc-4ecc-de56-33a989c87907"
      },
      "id": "V1ByM-pkal-m",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ditto-talkinghead'...\n",
            "remote: Enumerating objects: 226, done.\u001b[K\n",
            "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 226 (delta 34), reused 129 (delta 23), pack-reused 63 (from 2)\u001b[K\n",
            "Receiving objects: 100% (226/226), 6.86 MiB | 46.24 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ditto-talkinghead/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTHxciNJbuQ9",
        "outputId": "608a6a90-e5ca-4a36-b8d7-5045b419fdca"
      },
      "id": "qTHxciNJbuQ9",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "core\t\t  inference.py\tscripts\n",
            "environment.yaml  LICENSE\tstream_pipeline_offline.py\n",
            "example\t\t  README.md\tstream_pipeline_online.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "N5N-EGjQ37kl"
      },
      "id": "N5N-EGjQ37kl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "!pip install \\\n",
        "    librosa \\\n",
        "    tqdm \\\n",
        "    filetype \\\n",
        "    imageio \\\n",
        "    opencv_python_headless \\\n",
        "    scikit-image \\\n",
        "    cython \\\n",
        "    cuda-python \\\n",
        "    imageio-ffmpeg \\\n",
        "    colored \\\n",
        "    polygraphy \\\n",
        "    numpy==2.0.1"
      ],
      "metadata": {
        "id": "FtuhJXENbx8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179fd252-8054-4aff-8f4f-edd90bea5e30"
      },
      "id": "FtuhJXENbx8k",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (2.37.2)\n",
            "Requirement already satisfied: opencv_python_headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.12/dist-packages (3.0.12)\n",
            "Requirement already satisfied: cuda-python in /usr/local/lib/python3.12/dist-packages (12.9.4)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: colored in /usr/local/lib/python3.12/dist-packages (2.3.1)\n",
            "Requirement already satisfied: polygraphy in /usr/local/lib/python3.12/dist-packages (0.49.26)\n",
            "Requirement already satisfied: numpy==2.0.1 in /usr/local/lib/python3.12/dist-packages (2.0.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio) (11.3.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: cuda-bindings~=12.9.4 in /usr/local/lib/python3.12/dist-packages (from cuda-python) (12.9.4)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings~=12.9.4->cuda-python) (1.3.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4exi8LW6b-Rz",
        "outputId": "2bc5cdd9-3a91-417c-cbf0-34273cba9f0b"
      },
      "id": "4exi8LW6b-Rz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=585cb723ef4135c31a146dd3f5f4af3e5905e1d7c6e02825d48ccd464bbc44eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/21/0c/c26e09dff860a9071683e279445262346e008a9a1d2142c4ad\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/digital-avatar/ditto-talkinghead checkpoints"
      ],
      "metadata": {
        "id": "PB4g_oOob_ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9ba725-f73f-4371-9afb-85b40733d6ad"
      },
      "id": "PB4g_oOob_ll",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'checkpoints'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 84 (delta 17), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (84/84), 23.07 KiB | 1.36 MiB/s, done.\n",
            "Filtering content: 100% (40/40), 6.45 GiB | 52.41 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ditto-talkinghead/inference.py \\\n",
        "    --data_root \"./checkpoints/ditto_trt_Ampere_Plus\" \\\n",
        "    --cfg_pkl \"./checkpoints/ditto_cfg/v0.4_hubert_cfg_trt.pkl\" \\\n",
        "    --audio_path \"./example/audio.wav\" \\\n",
        "    --source_path \"./example/image.png\" \\\n",
        "    --output_path \"./tmp/result.mp4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9GS4dst5vqq",
        "outputId": "7235794c-9ff0-483c-a1ac-f09576ad8bc0"
      },
      "id": "G9GS4dst5vqq",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.12/dist-packages/numpy/_core/include/numpy/ndarraytypes.h:1909\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.12/dist-packages/numpy/_core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.12/dist-packages/numpy/_core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/root/.pyxbld/temp.linux-x86_64-cpython-312/content/ditto-talkinghead/core/utils/blend/blend.c:1259\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.12/dist-packages/numpy/_core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "<frozen importlib._bootstrap_external>:1301: FutureWarning: The cuda.cuda module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.driver module instead.\n",
            "<frozen importlib._bootstrap_external>:1301: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n",
            "<frozen importlib._bootstrap_external>:1301: FutureWarning: The cuda.nvrtc module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.nvrtc module instead.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ditto-talkinghead/core/utils/tensorrt_utils.py\", line 12, in <module>\n",
            "    import tensorrt as trt\n",
            "ModuleNotFoundError: No module named 'tensorrt'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ditto-talkinghead/inference.py\", line 80, in <module>\n",
            "    SDK = StreamSDK(cfg_pkl, data_root)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ditto-talkinghead/stream_pipeline_offline.py\", line 35, in __init__\n",
            "    self.avatar_registrar = AvatarRegistrar(**avatar_registrar_cfg)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ditto-talkinghead/core/atomic_components/avatar_registrar.py\", line 52, in __init__\n",
            "    self.source2info = Source2Info(\n",
            "                       ^^^^^^^^^^^^\n",
            "  File \"/content/ditto-talkinghead/core/atomic_components/source2info.py\", line 59, in __init__\n",
            "    self.insightface_det = InsightFaceDet(**insightface_det_cfg)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ditto-talkinghead/core/aux_models/insightface_det.py\", line 62, in __init__\n",
            "    self.model, self.model_type = load_model(model_path, device=device, **kwargs)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ditto-talkinghead/core/utils/load_model.py\", line 20, in load_model\n",
            "    from .tensorrt_utils import TRTWrapper\n",
            "  File \"/content/ditto-talkinghead/core/utils/tensorrt_utils.py\", line 18, in <module>\n",
            "    ctypes.CDLL(os.path.join(trt_libs_path, \"libnvinfer_plugin.so.8\"))\n",
            "  File \"/usr/lib/python3.12/ctypes/__init__.py\", line 379, in __init__\n",
            "    self._handle = _dlopen(self._name, mode)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "OSError: libcudnn.so.8: cannot open shared object file: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ea62d9",
        "outputId": "fd0e8cc5-2399-495d-dccd-3b73aec9bab4"
      },
      "source": [
        "!pip install nvidia-pyindex"
      ],
      "id": "a8ea62d9",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8419 sha256=71851bfa8cd230894b379e65a22938b2b9236571cb328c75dac562f3207ae35c\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/2d/7f/d86cb060a9c51fb933aa4fe0d2f73ffe8df2bd0b58d3d2bba4\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77a7017e",
        "outputId": "2b50253a-ccb4-4fec-b30b-68c2fc4355b8"
      },
      "source": [
        "!pip install nvidia-tensorrt"
      ],
      "id": "77a7017e",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl.metadata (596 bytes)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Downloading tensorrt-10.14.1.48.post1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13==10.14.1.48.post1 (from tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu13-10.14.1.48.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_libs==10.14.1.48.post1 (from tensorrt_cu13==10.14.1.48.post1->tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu13_libs-10.14.1.48.post1.tar.gz (726 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_bindings==10.14.1.48.post1 (from tensorrt_cu13==10.14.1.48.post1->tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu13_bindings-10.14.1.48.post1-cp312-none-manylinux_2_28_x86_64.whl.metadata (612 bytes)\n",
            "Collecting cuda-toolkit<14,>=13 (from cuda-toolkit[cudart]<14,>=13->tensorrt_cu13_libs==10.14.1.48.post1->tensorrt_cu13==10.14.1.48.post1->tensorrt->nvidia-tensorrt)\n",
            "  Downloading cuda_toolkit-13.0.1-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting nvidia-cuda-runtime==13.0.88.* (from cuda-toolkit[cudart]<14,>=13->tensorrt_cu13_libs==10.14.1.48.post1->tensorrt_cu13==10.14.1.48.post1->tensorrt->nvidia-tensorrt)\n",
            "  Downloading nvidia_cuda_runtime-13.0.88-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Downloading tensorrt_cu13_bindings-10.14.1.48.post1-cp312-none-manylinux_2_28_x86_64.whl (879 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.9/879.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_toolkit-13.0.1-py2.py3-none-any.whl (2.4 kB)\n",
            "Downloading nvidia_cuda_runtime-13.0.88-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu13, tensorrt_cu13_libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.14.1.48.post1-py2.py3-none-any.whl size=16738 sha256=83572fd6ba5458c64e1685210240f762394ed59ba81f443e5d020ad22dd8f444\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/bf/f0/25cc47daa9fb0f17d17396b6c0201a4779b8b479974bd13cbd\n",
            "  Building wheel for tensorrt_cu13 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13: filename=tensorrt_cu13-10.14.1.48.post1-py2.py3-none-any.whl size=18162 sha256=ee1970bc67265397b79610f521f91f6b1f46d1a2297412c486fc5e098a0fa985\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/26/6f/efb7e2860ca12b2ddf1b73f69e5566e4e7aee35a235ac37cc3\n",
            "  Building wheel for tensorrt_cu13_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13_libs: filename=tensorrt_cu13_libs-10.14.1.48.post1-py2.py3-none-manylinux_2_28_x86_64.whl size=3437501033 sha256=f55d59e9f93ebe0967c4bc108fb4068e74cdbc50bef3e6c9936e92f21cf11352\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/3b/70/effac73d572fe290ae73f8f1976024e31372d53399144cba8f\n",
            "Successfully built tensorrt tensorrt_cu13 tensorrt_cu13_libs\n",
            "Installing collected packages: tensorrt_cu13_bindings, cuda-toolkit, nvidia-cuda-runtime, tensorrt_cu13_libs, tensorrt_cu13, tensorrt, nvidia-tensorrt\n",
            "  Attempting uninstall: cuda-toolkit\n",
            "    Found existing installation: cuda-toolkit 12.9.1\n",
            "    Uninstalling cuda-toolkit-12.9.1:\n",
            "      Successfully uninstalled cuda-toolkit-12.9.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.10.0 requires cuda-toolkit[nvcc,nvrtc]==12.*, but you have cuda-toolkit 13.0.1 which is incompatible.\n",
            "libcuml-cu12 25.10.0 requires cuda-toolkit[cublas,cufft,curand,cusolver,cusparse]==12.*, but you have cuda-toolkit 13.0.1 which is incompatible.\n",
            "libraft-cu12 25.10.0 requires cuda-toolkit[cublas,curand,cusolver,cusparse]==12.*, but you have cuda-toolkit 13.0.1 which is incompatible.\n",
            "cuml-cu12 25.10.0 requires cuda-toolkit[cublas,cufft,curand,cusolver,cusparse]==12.*, but you have cuda-toolkit 13.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cuda-toolkit-13.0.1 nvidia-cuda-runtime-13.0.88 nvidia-tensorrt-99.0.0 tensorrt-10.14.1.48.post1 tensorrt_cu13-10.14.1.48.post1 tensorrt_cu13_bindings-10.14.1.48.post1 tensorrt_cu13_libs-10.14.1.48.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb724084",
        "outputId": "ebb32b7b-c19a-433a-ec82-c726b0f7089e"
      },
      "source": [
        "# Uninstall the conflicting CUDA 13 components\n",
        "!pip uninstall -y nvidia-tensorrt tensorrt tensorrt_cu13 tensorrt_cu13_bindings tensorrt_cu13_libs cuda-toolkit nvidia-cuda-runtime\n",
        "\n",
        "# Clear pip cache to ensure fresh downloads if needed\n",
        "!pip cache purge"
      ],
      "id": "cb724084",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: nvidia-tensorrt 99.0.0\n",
            "Uninstalling nvidia-tensorrt-99.0.0:\n",
            "  Successfully uninstalled nvidia-tensorrt-99.0.0\n",
            "Found existing installation: tensorrt 10.14.1.48.post1\n",
            "Uninstalling tensorrt-10.14.1.48.post1:\n",
            "  Successfully uninstalled tensorrt-10.14.1.48.post1\n",
            "Found existing installation: tensorrt_cu13 10.14.1.48.post1\n",
            "Uninstalling tensorrt_cu13-10.14.1.48.post1:\n",
            "  Successfully uninstalled tensorrt_cu13-10.14.1.48.post1\n",
            "Found existing installation: tensorrt_cu13_bindings 10.14.1.48.post1\n",
            "Uninstalling tensorrt_cu13_bindings-10.14.1.48.post1:\n",
            "  Successfully uninstalled tensorrt_cu13_bindings-10.14.1.48.post1\n",
            "Found existing installation: tensorrt_cu13_libs 10.14.1.48.post1\n",
            "Uninstalling tensorrt_cu13_libs-10.14.1.48.post1:\n",
            "  Successfully uninstalled tensorrt_cu13_libs-10.14.1.48.post1\n",
            "Found existing installation: cuda-toolkit 13.0.1\n",
            "Uninstalling cuda-toolkit-13.0.1:\n",
            "  Successfully uninstalled cuda-toolkit-13.0.1\n",
            "Found existing installation: nvidia-cuda-runtime 13.0.88\n",
            "Uninstalling nvidia-cuda-runtime-13.0.88:\n",
            "  Successfully uninstalled nvidia-cuda-runtime-13.0.88\n",
            "Files removed: 87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7b30348",
        "outputId": "b194c8fa-6aa7-4774-96d2-e48c715f66a6"
      },
      "source": [
        "# Try installing a specific TensorRT version known to work with CUDA 12, e.g., TensorRT 8.6.1 for CUDA 12\n",
        "# Note: This might require finding the exact pip package name if 'nvidia-tensorrt==8.6.1' is not it.\n",
        "# Based on common usage, sometimes 'tensorrt' (not 'nvidia-tensorrt') is used with direct CUDA versioning.\n",
        "# Let's try installing tensorrt directly with a CUDA 12 dependency, if a package exists.\n",
        "# If this fails, I might need to adjust the approach to try to force CUDA 12 first.\n",
        "\n",
        "# A common pattern is to install a specific 'tensorrt' version that is built against a specific CUDA version\n",
        "# However, PyPI packages like 'tensorrt' often are just wrappers or meta-packages. 'nvidia-tensorrt' is the official one.\n",
        "# The error from earlier 'nvidia-tensorrt==8.6.1 (from versions: 0.0.1.dev4, 0.0.1.dev5, 99.0.0)' indicates 8.6.1 might not be a valid version for 'nvidia-tensorrt'.\n",
        "# I will try to install 'nvidia-tensorrt' again, but explicitly tell it to use a CUDA 12 specific variant if available, which is often not directly possible via pip.\n",
        "\n",
        "# Given the persistent CUDA 13 installation with nvidia-tensorrt-99.0.0, the best approach might be to try a specific `tensorrt` package directly that specifies cu12.\n",
        "# However, such packages are not always readily available on PyPI. Another strategy is to ensure CUDA 12 is installed *before* TensorRT.\n",
        "\n",
        "# Let's try installing a cuda-toolkit 12 first, and then nvidia-tensorrt, hoping it respects the existing CUDA.\n",
        "!pip install cuda-toolkit==12.2.2\n",
        "!pip install nvidia-tensorrt"
      ],
      "id": "b7b30348",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cuda-toolkit==12.2.2\n",
            "  Downloading cuda_toolkit-12.2.2-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Downloading cuda_toolkit-12.2.2-py2.py3-none-any.whl (2.2 kB)\n",
            "Installing collected packages: cuda-toolkit\n",
            "Successfully installed cuda-toolkit-12.2.2\n",
            "Collecting nvidia-tensorrt\n",
            "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl.metadata (596 bytes)\n",
            "Collecting tensorrt (from nvidia-tensorrt)\n",
            "  Downloading tensorrt-10.14.1.48.post1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13==10.14.1.48.post1 (from tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu13-10.14.1.48.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_libs==10.14.1.48.post1 (from tensorrt_cu13==10.14.1.48.post1->tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu13_libs-10.14.1.48.post1.tar.gz (726 bytes)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu13_bindings==10.14.1.48.post1 (from tensorrt_cu13==10.14.1.48.post1->tensorrt->nvidia-tensorrt)\n",
            "  Downloading tensorrt_cu13_bindings-10.14.1.48.post1-cp312-none-manylinux_2_28_x86_64.whl.metadata (612 bytes)\n",
            "Collecting cuda-toolkit<14,>=13 (from cuda-toolkit[cudart]<14,>=13->tensorrt_cu13_libs==10.14.1.48.post1->tensorrt_cu13==10.14.1.48.post1->tensorrt->nvidia-tensorrt)\n",
            "  Downloading cuda_toolkit-13.0.1-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting nvidia-cuda-runtime==13.0.88.* (from cuda-toolkit[cudart]<14,>=13->tensorrt_cu13_libs==10.14.1.48.post1->tensorrt_cu13==10.14.1.48.post1->tensorrt->nvidia-tensorrt)\n",
            "  Downloading nvidia_cuda_runtime-13.0.88-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
            "Downloading tensorrt_cu13_bindings-10.14.1.48.post1-cp312-none-manylinux_2_28_x86_64.whl (879 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.9/879.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cuda_toolkit-13.0.1-py2.py3-none-any.whl (2.4 kB)\n",
            "Downloading nvidia_cuda_runtime-13.0.88-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu13, tensorrt_cu13_libs\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.14.1.48.post1-py2.py3-none-any.whl size=16738 sha256=22e3e8f1c2b561f182eaa345732bd333c68e058a49d7bf695ba43757a161d40c\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/bf/f0/25cc47daa9fb0f17d17396b6c0201a4779b8b479974bd13cbd\n",
            "  Building wheel for tensorrt_cu13 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13: filename=tensorrt_cu13-10.14.1.48.post1-py2.py3-none-any.whl size=18162 sha256=3de5387f020cf99077c49729bc7a944993bfbb19174e7715183fd0265d7edfbe\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/26/6f/efb7e2860ca12b2ddf1b73f69e5566e4e7aee35a235ac37cc3\n",
            "  Building wheel for tensorrt_cu13_libs (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu13_libs: filename=tensorrt_cu13_libs-10.14.1.48.post1-py2.py3-none-manylinux_2_28_x86_64.whl size=3437501033 sha256=f55d59e9f93ebe0967c4bc108fb4068e74cdbc50bef3e6c9936e92f21cf11352\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/3b/70/effac73d572fe290ae73f8f1976024e31372d53399144cba8f\n",
            "Successfully built tensorrt tensorrt_cu13 tensorrt_cu13_libs\n",
            "Installing collected packages: tensorrt_cu13_bindings, cuda-toolkit, nvidia-cuda-runtime, tensorrt_cu13_libs, tensorrt_cu13, tensorrt, nvidia-tensorrt\n",
            "  Attempting uninstall: cuda-toolkit\n",
            "    Found existing installation: cuda-toolkit 12.2.2\n",
            "    Uninstalling cuda-toolkit-12.2.2:\n",
            "      Successfully uninstalled cuda-toolkit-12.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.10.0 requires cuda-toolkit[nvcc,nvrtc]==12.*, but you have cuda-toolkit 13.0.1 which is incompatible.\n",
            "libcuml-cu12 25.10.0 requires cuda-toolkit[cublas,cufft,curand,cusolver,cusparse]==12.*, but you have cuda-toolkit 13.0.1 which is incompatible.\n",
            "libraft-cu12 25.10.0 requires cuda-toolkit[cublas,curand,cusolver,cusparse]==12.*, but you have cuda-toolkit 13.0.1 which is incompatible.\n",
            "cuml-cu12 25.10.0 requires cuda-toolkit[cublas,cufft,curand,cusolver,cusparse]==12.*, but you have cuda-toolkit 13.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cuda-toolkit-13.0.1 nvidia-cuda-runtime-13.0.88 nvidia-tensorrt-99.0.0 tensorrt-10.14.1.48.post1 tensorrt_cu13-10.14.1.48.post1 tensorrt_cu13_bindings-10.14.1.48.post1 tensorrt_cu13_libs-10.14.1.48.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9588cd3f",
        "outputId": "a6d292b4-c0d9-4837-d88e-0e3680032819"
      },
      "source": [
        "!python ditto-talkinghead/inference.py \\\n",
        "  --data_root \"./checkpoints/ditto_pytorch\" \\\n",
        "  --cfg_pkl \"./checkpoints/ditto_cfg/v0.4_hubert_cfg_pytorch.pkl\" \\\n",
        "  --audio_path \"ditto-talkinghead/example/audio.wav\" \\\n",
        "  --source_path \"ditto-talkinghead/example/image.png\" \\\n",
        "  --output_path \"./tmp/result.mp4\""
      ],
      "id": "9588cd3f",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "2025-11-23 14:31:01.430775: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763908261.451032   19609 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763908261.457126   19609 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763908261.472917   19609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763908261.472943   19609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763908261.472947   19609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763908261.472951   19609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-23 14:31:01.477751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/usr/local/lib/python3.12/dist-packages/jaxlib/plugin_support.py:71: RuntimeWarning: JAX plugin jax_cuda12_plugin version 0.7.2 is installed, but it is not compatible with the installed jaxlib version 0.7.1, so it will not be used.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1763908267.346231   19609 task_runner.cc:85] GPU suport is not available: INTERNAL: ; RET_CHECK failure (mediapipe/gpu/gl_context_egl.cc:84) egl_initializedUnable to initialize EGL\n",
            "W0000 00:00:1763908267.346740   19609 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "W0000 00:00:1763908267.354340   19672 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "W0000 00:00:1763908267.376748   19672 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
            "/usr/local/lib/python3.12/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
            "  warnings.warn(\n",
            "==================== setup kwargs ====================\n",
            "max_size <class 'int'> 1920\n",
            "template_n_frames <class 'int'> -1\n",
            "crop_scale <class 'float'> 2.3\n",
            "crop_vx_ratio <class 'int'> 0\n",
            "crop_vy_ratio <class 'float'> -0.125\n",
            "crop_flag_do_rot <class 'bool'> True\n",
            "smo_k_s <class 'int'> 13\n",
            "emo <class 'numpy.ndarray'> (600, 8)\n",
            "eye_f0_mode <class 'bool'> False\n",
            "ch_info <class 'dict'>\n",
            "overlap_v2 <class 'int'> 10\n",
            "fix_kp_cond <class 'int'> 1\n",
            "fix_kp_cond_dim <class 'list'> [0, 202]\n",
            "sampling_timesteps <class 'int'> 50\n",
            "online_mode <class 'bool'> False\n",
            "v_min_max_for_clip <class 'numpy.ndarray'> (4, 265)\n",
            "smo_k_d <class 'int'> 3\n",
            "N_d <class 'int'> -1\n",
            "use_d_keys <class 'NoneType'> None\n",
            "relative_d <class 'bool'> True\n",
            "drive_eye <class 'NoneType'> None\n",
            "delta_eye_arr <class 'numpy.ndarray'> (15, 63)\n",
            "delta_eye_open_n <class 'int'> 0\n",
            "fade_type <class 'str'> d0\n",
            "fade_out_keys <class 'list'> ['exp']\n",
            "flag_stitching <class 'bool'> True\n",
            "overall_ctrl_info <class 'dict'> {'delta_pitch': 2}\n",
            "==================================================\n",
            "\u001b[0;93m2025-11-23 14:31:13.714195968 [W:onnxruntime:, execution_frame.cc:874 VerifyOutputSizes] Expected shape from model of {800,10} does not match actual shape of {512,10} for output 500\u001b[m\n",
            "\u001b[0;93m2025-11-23 14:31:13.714343480 [W:onnxruntime:, execution_frame.cc:874 VerifyOutputSizes] Expected shape from model of {800,4} does not match actual shape of {512,4} for output 497\u001b[m\n",
            "\u001b[0;93m2025-11-23 14:31:13.714475490 [W:onnxruntime:, execution_frame.cc:874 VerifyOutputSizes] Expected shape from model of {800,1} does not match actual shape of {512,1} for output 494\u001b[m\n",
            "\u001b[0;93m2025-11-23 14:31:13.719373269 [W:onnxruntime:, execution_frame.cc:874 VerifyOutputSizes] Expected shape from model of {3200,10} does not match actual shape of {2048,10} for output 477\u001b[m\n",
            "\u001b[0;93m2025-11-23 14:31:13.719763198 [W:onnxruntime:, execution_frame.cc:874 VerifyOutputSizes] Expected shape from model of {3200,4} does not match actual shape of {2048,4} for output 474\u001b[m\n",
            "\u001b[0;93m2025-11-23 14:31:13.720120799 [W:onnxruntime:, execution_frame.cc:874 VerifyOutputSizes] Expected shape from model of {3200,1} does not match actual shape of {2048,1} for output 471\u001b[m\n",
            "\u001b[0;93m2025-11-23 14:31:13.737907013 [W:onnxruntime:, execution_frame.cc:874 VerifyOutputSizes] Expected shape from model of {12800,10} does not match actual shape of {8192,10} for output 454\u001b[m\n",
            "\u001b[0;93m2025-11-23 14:31:13.739457794 [W:onnxruntime:, execution_frame.cc:874 VerifyOutputSizes] Expected shape from model of {12800,4} does not match actual shape of {8192,4} for output 451\u001b[m\n",
            "\u001b[0;93m2025-11-23 14:31:13.740822000 [W:onnxruntime:, execution_frame.cc:874 VerifyOutputSizes] Expected shape from model of {12800,1} does not match actual shape of {8192,1} for output 448\u001b[m\n",
            "writer: 0it [00:00, ?it/s]\n",
            "dit: 0it [00:00, ?it/s]\u001b[A\n",
            "dit: 2it [00:02,  1.02s/it]\u001b[A\n",
            "dit: 3it [00:03,  1.36s/it]\u001b[A\n",
            "dit: 4it [00:05,  1.53s/it]\u001b[A\n",
            "dit: 5it [00:07,  1.73s/it]\u001b[A\n",
            "dit: 6it [00:11,  1.95s/it]\n",
            "writer: 394it [02:29,  2.64it/s]\n",
            "ffmpeg -loglevel error -y -i \"./tmp/result.mp4.tmp.mp4\" -i \"ditto-talkinghead/example/audio.wav\" -map 0:v -map 1:a -c:v copy -c:a aac \"./tmp/result.mp4\"\n",
            "./tmp/result.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRBPwHSUG-Ty"
      },
      "id": "NRBPwHSUG-Ty",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}